{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"0nTfTT9fPl6-","outputId":"2b87e45f-1ca3-4e6f-d2a8-2545196ab343"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","140 image(s) saved to Dataset\\None\n"]}],"source":["import cv2\n","import os\n","\n","label_name = input(\"Enter the label name:-\")//27\n","num_samples = int(input(\"Enter the number of samples:- \")) //140\n","\n","IMG_SAVE_PATH = 'Dataset'\n","IMG_CLASS_PATH = os.path.join(IMG_SAVE_PATH, label_name)\n","\n","try:\n","    os.makedirs(IMG_SAVE_PATH, exist_ok=True)\n","    os.makedirs(IMG_CLASS_PATH, exist_ok=True)\n","except OSError as e:\n","    print(\"Error: %s - %s.\" % (e.filename, e.strerror))\n","\n","cap = cv2.VideoCapture(0)\n","\n","start = False\n","count = 0\n","\n","while True:\n","    ret, frame = cap.read()\n","    if not ret:\n","        continue\n","\n","    if count == num_samples:\n","        break\n","\n","    frame = cv2.flip(frame, 1)\n","    cv2.rectangle(frame, (300, 50), (600, 350), (255, 255, 255), 2)\n","\n","    if start:\n","        roi = frame[50:350, 300:600] #region of intrest\n","\n","        # Save the captured image without preprocessing\n","        save_path = os.path.join(IMG_CLASS_PATH, '{}{}.jpg'.format(label_name, count + 1))\n","        cv2.imwrite(save_path, roi)\n","\n","        count += 1\n","\n","    font = cv2.FONT_HERSHEY_SIMPLEX\n","    cv2.putText(frame, \"Collecting {}\".format(count), (5, 50), font, 0.7, (0, 255, 255), 2, cv2.LINE_AA)\n","\n","    cv2.imshow(\"Collecting images\", frame)\n","\n","    k = cv2.waitKey(10)\n","    if k == ord('a'):\n","        start = not start\n","\n","    if k == ord('q'):\n","        break\n","\n","print(\"\\n{} image(s) saved to {}\".format(count, IMG_CLASS_PATH))\n","cap.release()\n","cv2.destroyAllWindows()\n"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":33271,"status":"ok","timestamp":1712924364987,"user":{"displayName":"Major Project","userId":"05785590010204809709"},"user_tz":-330},"id":"Ax3pRFNIPvxW","outputId":"53f512b5-04ad-4f2e-dcc0-19097b27f385"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive') #google collab"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":234221,"status":"ok","timestamp":1712924800731,"user":{"displayName":"Major Project","userId":"05785590010204809709"},"user_tz":-330},"id":"4_scZuc5Pl7A","outputId":"c55adb2e-2d49-4541-bc41-a1c9d4c3d34c"},"outputs":[{"name":"stderr","output_type":"stream","text":["Processing Z: 100%|██████████| 140/140 [00:08<00:00, 16.82it/s]\n","Processing W: 100%|██████████| 140/140 [00:07<00:00, 19.55it/s]\n","Processing V: 100%|██████████| 140/140 [00:06<00:00, 20.63it/s]\n","Processing U: 100%|██████████| 140/140 [00:06<00:00, 20.80it/s]\n","Processing R: 100%|██████████| 140/140 [00:11<00:00, 11.79it/s]\n","Processing Y: 100%|██████████| 140/140 [00:11<00:00, 12.04it/s]\n","Processing znone: 100%|██████████| 140/140 [00:13<00:00, 10.17it/s]\n","Processing T: 100%|██████████| 140/140 [00:06<00:00, 20.59it/s]\n","Processing S: 100%|██████████| 140/140 [00:06<00:00, 20.34it/s]\n","Processing X: 100%|██████████| 140/140 [00:06<00:00, 21.41it/s]\n","Processing K: 100%|██████████| 140/140 [00:11<00:00, 11.83it/s]\n","Processing M: 100%|██████████| 140/140 [00:06<00:00, 21.61it/s]\n","Processing N: 100%|██████████| 140/140 [00:06<00:00, 20.76it/s]\n","Processing H: 100%|██████████| 140/140 [00:17<00:00,  8.07it/s]\n","Processing J: 100%|██████████| 140/140 [00:06<00:00, 21.17it/s]\n","Processing Q: 100%|██████████| 140/140 [00:06<00:00, 20.34it/s]\n","Processing L: 100%|██████████| 140/140 [00:13<00:00, 10.72it/s]\n","Processing O: 100%|██████████| 140/140 [00:06<00:00, 20.25it/s]\n","Processing P: 100%|██████████| 140/140 [00:12<00:00, 11.40it/s]\n","Processing I: 100%|██████████| 140/140 [00:07<00:00, 18.85it/s]\n","Processing F: 100%|██████████| 140/140 [00:06<00:00, 21.56it/s]\n","Processing G: 100%|██████████| 140/140 [00:06<00:00, 20.97it/s]\n","Processing C: 100%|██████████| 140/140 [00:07<00:00, 19.97it/s]\n","Processing B: 100%|██████████| 140/140 [00:06<00:00, 21.37it/s]\n","Processing D: 100%|██████████| 140/140 [00:07<00:00, 19.66it/s]\n","Processing E: 100%|██████████| 140/140 [00:07<00:00, 19.57it/s]\n","Processing A: 100%|██████████| 140/140 [00:06<00:00, 20.41it/s]"]},{"name":"stdout","output_type":"stream","text":["Preprocessing completed.\n"]},{"name":"stderr","output_type":"stream","text":["\n"]}],"source":["#Preprocessing\n","import os\n","import cv2\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from tqdm import tqdm\n","\n","def preprocess_image(image):\n","    # Apply Gaussian blur to reduce noise\n","    blurred_image = cv2.GaussianBlur(image, (1, 1), 0)\n","\n","    # Convert the image to RGB\n","    rgb_image = cv2.cvtColor(blurred_image, cv2.COLOR_BGR2RGB)\n","\n","    # Split the RGB channels\n","    r, g, b = cv2.split(rgb_image)\n","\n","    # Apply adaptive thresholding to each channel\n","    _, thresholded_r = cv2.threshold(r, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n","    _, thresholded_g = cv2.threshold(g, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n","    _, thresholded_b = cv2.threshold(b, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n","\n","    # Merge the thresholded channels back into an RGB image\n","    thresholded_image = cv2.merge([thresholded_r, thresholded_g, thresholded_b])\n","\n","    # Resize the image to match model input size\n","    resized_image = cv2.resize(thresholded_image, (224, 224))\n","\n","    # Normalize pixel values to range [0, 1]\n","    normalized_image = resized_image / 255.0\n","\n","    # Add batch dimension\n","    reshaped_image = np.expand_dims(normalized_image, axis=0)\n","\n","    return reshaped_image\n","\n","# def preprocess_image(image):\n","#     # Apply Gaussian blur to reduce noise\n","#     blurred_image = cv2.GaussianBlur(image, (1, 1), 0)\n","\n","#     # Convert the image to RGB\n","#     rgb_image = cv2.cvtColor(blurred_image, cv2.COLOR_BGR2RGB)\n","\n","#     # Resize the image to match model input size\n","#     resized_image = cv2.resize(rgb_image, (64, 64))\n","\n","#     # Normalize pixel values to range [0, 1]\n","#     normalized_image = resized_image / 255.0\n","\n","#     return normalized_image\n","\n","def preprocess_images_in_directory(input_dir, output_dir):\n","    # Create the output directory if it doesn't exist\n","    os.makedirs(output_dir, exist_ok=True)\n","\n","    for label in os.listdir(input_dir):\n","        label_path = os.path.join(input_dir, label)\n","        if os.path.isdir(label_path):\n","            for filename in tqdm(os.listdir(label_path), desc=f\"Processing {label}\"):\n","                if filename.endswith('.jpg') or filename.endswith('.jpeg') or filename.endswith('.png'):\n","                    image_path = os.path.join(label_path, filename)\n","                    image = cv2.imread(image_path)\n","                    if image is not None:\n","                        preprocessed_image = preprocess_image(image)\n","                        output_path = os.path.join(output_dir, label, filename)\n","                        os.makedirs(os.path.dirname(output_path), exist_ok=True)\n","                        cv2.imwrite(output_path, (preprocessed_image[0] * 255).astype(np.uint8))  # Convert to uint8 before saving\n","                    else:\n","                        print(f\"Error loading image: {image_path}\")\n","\n","if __name__ == \"__main__\":\n","    input_dir = \"/content/drive/MyDrive/Colab Notebooks/PROJ_HCI/Dataset\"  # Specify the input directory containing images\n","    output_dir = \"/content/drive/MyDrive/Colab Notebooks/PROJ_HCI/PreprocessedDataset\"  # Specify the output directory for preprocessed images\n","\n","    preprocess_images_in_directory(input_dir, output_dir)\n","\n","    print(\"Preprocessing completed.\")\n"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":77209,"status":"ok","timestamp":1712925063635,"user":{"displayName":"Major Project","userId":"05785590010204809709"},"user_tz":-330},"id":"GqRT8A9ePl7B","outputId":"d789898f-8403-47da-e327-fe7677cf31fb"},"outputs":[{"name":"stdout","output_type":"stream","text":["Dataset split completed.\n","Number of images in train directory: 3024\n","Number of images in test directory: 378\n","Number of images in val directory: 378\n"]}],"source":["#splitting\n","import os\n","import shutil\n","from sklearn.model_selection import train_test_split\n","\n","def split_dataset(input_dir, output_dir, test_size=0.1, val_size=0.1, random_state=42):\n","    # Create output directories if they don't exist\n","    train_dir = os.path.join(output_dir, 'train')\n","    test_dir = os.path.join(output_dir, 'test')\n","    val_dir = os.path.join(output_dir, 'val')\n","    for directory in [train_dir, test_dir, val_dir]:\n","        os.makedirs(directory, exist_ok=True)\n","\n","    for label in os.listdir(input_dir):\n","        label_path = os.path.join(input_dir, label)\n","        if os.path.isdir(label_path):\n","            # Split images for the current label\n","            images = os.listdir(label_path)\n","            X_train, X_test_val = train_test_split(images, test_size=test_size+val_size, random_state=random_state)\n","            X_val, X_test = train_test_split(X_test_val, test_size=val_size/(test_size+val_size), random_state=random_state)\n","\n","            # Copy images to train, test, and val directories\n","            for filename in X_train:\n","                src = os.path.join(label_path, filename)\n","                dst = os.path.join(train_dir, label)\n","                os.makedirs(dst, exist_ok=True)\n","                shutil.copy(src, dst)\n","            for filename in X_test:\n","                src = os.path.join(label_path, filename)\n","                dst = os.path.join(test_dir, label)\n","                os.makedirs(dst, exist_ok=True)\n","                shutil.copy(src, dst)\n","            for filename in X_val:\n","                src = os.path.join(label_path, filename)\n","                dst = os.path.join(val_dir, label)\n","                os.makedirs(dst, exist_ok=True)\n","                shutil.copy(src, dst)\n","\n","if __name__ == \"__main__\":\n","    input_dir = \"/content/drive/MyDrive/Colab Notebooks/PROJ_HCI/PreprocessedDataset\"  # Specify the input directory containing preprocessed images\n","    output_dir = \"/content/drive/MyDrive/Colab Notebooks/PROJ_HCI/SplitDataset\"  # Specify the output directory for split dataset\n","\n","    split_dataset(input_dir, output_dir)\n","\n","    print(\"Dataset split completed.\")\n","import os\n","\n","def count_images_in_directory(directory):\n","    count = 0\n","    for root, dirs, files in os.walk(directory):\n","        for file in files:\n","            if file.endswith('.jpg') or file.endswith('.jpeg') or file.endswith('.png'):\n","                count += 1\n","    return count\n","\n","if __name__ == \"__main__\":\n","    output_dir = r\"C:\\Users\\janas\\Downloads\\PROJ_HCI_Collab-20240412T130910Z-001\\PROJ_HCI_Collab\\SplitDataset\"  # Specify the output directory for split dataset\n","\n","    train_dir = os.path.join(output_dir, 'train')\n","    test_dir = os.path.join(output_dir, 'test')\n","    val_dir = os.path.join(output_dir, 'val')\n","\n","    num_train_images = count_images_in_directory(train_dir)\n","    num_test_images = count_images_in_directory(test_dir)\n","    num_val_images = count_images_in_directory(val_dir)\n","\n","    print(\"Number of images in train directory:\", num_train_images)\n","    print(\"Number of images in test directory:\", num_test_images)\n","    print(\"Number of images in val directory:\", num_val_images)\n"]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.9"}},"nbformat":4,"nbformat_minor":0}
